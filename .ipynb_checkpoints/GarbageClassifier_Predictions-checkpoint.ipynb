{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class CustomImageTextDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform, tokenizer):\n",
    "        self.dataset = datasets.ImageFolder(image_dir, transform=transform) \n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]  \n",
    "        image_path, _ = self.dataset.imgs[idx]  # Get image filename\n",
    "\n",
    "        # Extract text from filename \n",
    "        file_name = os.path.basename(image_path)\n",
    "        text = os.path.splitext(file_name)[0]  # Remove extension\n",
    "        text = text.replace('_', ' ')  # Replace underscores with spaces\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "\n",
    "        # Tokenize text using DistilBERT\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class ResNetBERTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetBERTClassifier, self).__init__()\n",
    "\n",
    "        # Image feature extractor\n",
    "        self.resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "        # Freeze layers for transfer learning\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Remove the final layer\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.resnet_out_dim = 512  # Output feature size\n",
    "\n",
    "        # Text feature extracter\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.bert_out_dim = self.bert.config.hidden_size  \n",
    "        \n",
    "        # Freeze all layers except the last transformer layer\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            if \"transformer.layer.5\" in name:\n",
    "                param.requires_grad = True  \n",
    "            else:\n",
    "                param.requires_grad = False  \n",
    "\n",
    "        # Single FC layer for classification\n",
    "        self.classifier = nn.Linear(self.resnet_out_dim + self.bert_out_dim, num_classes)\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        # Image pathway\n",
    "        img_features = self.resnet(image)\n",
    "        img_features = F.normalize(img_features, p=2, dim=1)  # L2 normalization\n",
    "\n",
    "        # Text pathway\n",
    "        text_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        text_features = text_output[:, 0] \n",
    "        text_features = F.normalize(text_features, p=2, dim=1)  # L2 normalization\n",
    "\n",
    "        # Combine image and text features\n",
    "        combined_features = torch.cat((img_features, text_features), dim=1)\n",
    "\n",
    "        # Pass through the classifier\n",
    "        output = self.classifier(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to evaluate the model\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation needed\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = (torch.tensor(all_preds) == torch.tensor(all_labels)).sum().item() / len(all_labels)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'labels': all_labels,   # Return true labels\n",
    "        'predictions': all_preds  # Return predicted labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test data directory\n",
    "TEST_PATH   = \"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Test\"\n",
    "\n",
    "# Define transformations for the test images\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Load datasets\n",
    "test_dataset = CustomImageTextDataset(TEST_PATH, transform=transform, tokenizer=tokenizer)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = ResNetBERTClassifier(num_classes=4).to(device)\n",
    "\n",
    "# Load the best saved model weights\n",
    "model.load_state_dict(torch.load('./best_model.pth', map_location=device))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Evaluate on the test set\n",
    "eval_results = evaluate_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Evaluation Metrics\n",
    "print(\"\\n--- Evaluation Metrics on Test Set ---\")\n",
    "print(f\"Test Accuracy : {eval_results['accuracy']:.4f}\")\n",
    "print(f\"Precision     : {eval_results['precision']:.4f}\")\n",
    "print(f\"Recall        : {eval_results['recall']:.4f}\")\n",
    "print(f\"F1 Score      : {eval_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "def plot_confusion_matrix(true_labels, predictions):\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function using predictions and true labels\n",
    "plot_confusion_matrix(eval_results['labels'], eval_results['predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
